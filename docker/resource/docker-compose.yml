#version: '3.8'

services:
  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"

  kafka-format:
    image: apache/kafka:3.7.0
    environment:
      # ← 여기서 그냥 문자열로 고정
      KAFKA_CLUSTER_ID: "my-fixed-cluster-id-12345"
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka_data:/var/lib/kafka/data
    entrypoint:
      - /bin/bash
      - -lc
      - |
        if [ ! -f /var/lib/kafka/data/meta.properties ]; then
          echo "Formatting storage with Cluster ID: ${KAFKA_CLUSTER_ID}"
          /opt/kafka/bin/kafka-storage.sh format \
            -t "${KAFKA_CLUSTER_ID}" \
            -c /opt/kafka/config/kraft/server.properties
        else
          echo "meta.properties already exists. Skipping format."
        fi
    restart: "no"

  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: "1"

      # 리스너/애드버타이즈
      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://localhost:9092"

      # 컨트롤러 쿼럼(단일 노드)
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"

      # 개발용 복제/ISR 최소화
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"

      # 로그 경로 + 클러스터 ID(아래에서 생성해 주입)
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      KAFKA_CLUSTER_ID: "my-fixed-cluster-id-12345"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "bash", "-lc", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 10

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    ulimits:
      memlock:
        soft: -1
        hard: -1

  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
  mysql:
    image: mysql:8.0
    container_name: mysql
    restart: always
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: pass1234
      MYSQL_DATABASE: appdb
      MYSQL_USER: appuser
      MYSQL_PASSWORD: apppass
    volumes:
      - ./mysql-data:/var/lib/mysql

  rabbitmq:
    container_name: rabbitmq
    image: "rabbitmq:3-management"
    hostname: "rabbitmq"
    ports:
      - "15672:15672" # Management interface
      - "5672:5672"   # RabbitMQ client
  fluentbit:
    image: fluent/fluent-bit:2.1
    container_name: fluentbit
    volumes:
      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    depends_on:
      - elasticsearch
    ports:
      - "24224:24224"
      - "24224:24224/udp"
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    volumes:
      - ./otel-collector-config.yaml:/etc/otelcol/config.yaml
    command: [ "--config=/etc/otelcol/config.yaml" ]
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    depends_on:
      - zipkin

  zipkin:
    image: openzipkin/zipkin:latest
    container_name: zipkin
    ports:
      - "9411:9411"
  vault:
    image: hashicorp/vault:1.16
    container_name: vault
    ports:
      - "8200:8200"
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: root
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
    cap_add:
      - IPC_LOCK


volumes:
  kafka_data: {}